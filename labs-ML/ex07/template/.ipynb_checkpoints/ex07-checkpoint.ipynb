{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "## Classification Using SVM\n",
    "Load dataset. We will re-use the CERN dataset from project 1, available from https://inclass.kaggle.com/c/epfml-project-1/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,) (5000, 30)\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_csv_data\n",
    "\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "\n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cost and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_primal_objective(y, X, w, lambda_):\n",
    "    \"\"\"compute the full cost (the primal objective), that is loss plus regularizer.\n",
    "    X: the full dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    \"\"\"\n",
    "    z = np.zeros(y.shape)\n",
    "    e = X.dot(w)\n",
    "    print(w)\n",
    "    return np.sum(np.maximum(1 - y * e, z)) + lambda_/2 * np.linalg.norm(w, ord = 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y, X, w):\n",
    "    \"\"\"compute the training accuracy on the training set (can be called for test set as well).\n",
    "    X: the full dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    \"\"\"\n",
    "    len_y = y.shape[0]\n",
    "    y_pred = X.dot(w)\n",
    "    y_pred[np.where(y_pred <= 0)] = -1\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    pred_true = len_y - np.sum(np.abs((y - y_pred) / 2))\n",
    "    return pred_true / len_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the (stochastic) subgradient for the n-th summand of the SVM optimization objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stochastic_gradient(y, X, w, lambda_, n, num_examples):\n",
    "    \"\"\"compute the stochastic gradient of loss plus regularizer.\n",
    "    X: the dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    n: the index of the (one) datapoint we have sampled\n",
    "    num_examples: N\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    # Be careful about the constant N (size) term!\n",
    "    # The complete objective for SVM is a sum, not an average as in earlier SGD examples!\n",
    "    x_n, y_n = X[n], y[n]\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    if(1 - y_n * x_n.T.dot(w) <= 0) :\n",
    "        return lambda_ * w\n",
    "    else :\n",
    "        return lambda_ * w - (1/N) * y_n * x_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement stochastic gradient descent: Pick a data point uniformly at random and update w based on the gradient for the n-th summand of the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-123.377  -35.253  -85.6    -38.766   -2.531 -160.995    1.549   -3.016\n",
      "   -6.656 -170.225   -1.095   -1.413   -0.975  -39.707   -0.946    1.403\n",
      "  -43.493   -0.432   -1.908  -30.761   -2.914 -273.686   -2.     -44.513\n",
      "    1.036   -0.796  -42.512   -1.495    1.253  -87.025]\n",
      "iteration=0, cost=634966821.1183181\n",
      "[ 12.49472698 -29.70889024 -33.23069619  46.42314963  -3.65053859\n",
      "  23.40993932  -2.55787968  -1.03091645  22.89968081  19.24792633\n",
      "  -0.38776135   0.23450438  -4.08172407   7.40266591   0.6191532\n",
      "   2.42627579 -12.80301116   0.80768595  -2.15218529  12.92331465\n",
      "  -2.00117512 -64.74572277   0.07612782   4.91927308  -1.01650699\n",
      "  -5.75936259 -12.65091175  -3.00197483  -2.8020326   24.64844757]\n",
      "iteration=10000, cost=6864205.320013879\n",
      "[  7.84991039 -29.13625104 -30.36460387  45.02416723  -2.56640327\n",
      "  16.28345395  -1.39779906  -0.96423959  23.18599523  19.66801813\n",
      "  -0.39638187   0.2366645   -2.97823513   8.95495315   0.6252419\n",
      "   2.39931565 -11.93504304   0.81244825  -2.11975871  12.319019\n",
      "  -1.98586374 -56.85617226   0.09455499   3.95982643  -0.62204999\n",
      "  -5.31975676 -11.56308453  -1.90408212  -1.72208979  22.64828912]\n",
      "iteration=20000, cost=6042707.353607263\n",
      "[  6.04817816 -28.73617314 -28.5445671   43.75257124  -1.67548887\n",
      "  12.96338142  -0.47075982  -0.92081684  23.27099816  19.38116948\n",
      "  -0.40232956   0.2367269   -2.07967367   9.78530127   0.62572982\n",
      "   2.38752703 -11.46599724   0.81247997  -2.10592239  11.71142999\n",
      "  -1.97909156 -52.89309077   0.10557865   3.2719093   -0.13482216\n",
      "  -4.80819678 -10.68390538  -1.00426494  -0.83329874  21.06204912]\n",
      "iteration=30000, cost=5208968.74761731\n",
      "[  4.13075848 -28.21798899 -27.03622775  42.88438352  -1.46171531\n",
      "  11.46311828  -0.25098854  -0.88472133  23.30798379  19.72788318\n",
      "  -0.40176001   0.23556797  -1.86744147  10.43309965   0.62969036\n",
      "   2.37895096 -11.00718783   0.81583299  -2.08727691  11.404187\n",
      "  -1.97567322 -49.54426097   0.11637535   2.64632777  -0.16118866\n",
      "  -4.81793139 -10.38749344  -0.79461736  -0.63143129  20.30215384]\n",
      "iteration=40000, cost=4832968.248286705\n",
      "[ 2.98627581e+00 -2.79073503e+01 -2.60038337e+01  4.20850534e+01\n",
      " -1.24578579e+00  9.95074180e+00 -2.67572226e-02 -8.58697083e-01\n",
      "  2.32323796e+01  1.93226810e+01 -4.03742543e-01  2.36122506e-01\n",
      " -1.65159327e+00  1.08287295e+01  6.28011129e-01  2.36947141e+00\n",
      " -1.07465499e+01  8.16476348e-01 -2.08059204e+00  1.11325481e+01\n",
      " -1.97239779e+00 -4.75982278e+01  1.21519316e-01  2.30890833e+00\n",
      "  1.53774788e-01 -4.48769403e+00 -1.02701112e+01 -5.81053298e-01\n",
      " -4.21273829e-01  1.92406838e+01]\n",
      "iteration=50000, cost=4650773.133889874\n",
      "[  2.49268659 -27.63940095 -25.06055115  41.52810089  -0.98902968\n",
      "   9.21128534   0.23019363  -0.83439826  23.16851457  19.29915473\n",
      "  -0.40284768   0.23544659  -1.3979819   11.1951166    0.62919673\n",
      "   2.36304054 -10.45698843   0.81772025  -2.07134468  10.92936623\n",
      "  -1.97389698 -45.67384945   0.12857      2.02696024   0.36119993\n",
      "  -4.26920067  -9.98766862  -0.33003204  -0.1753685   18.56120915]\n",
      "iteration=60000, cost=4355501.088963692\n",
      "[  2.26841672 -27.38119083 -24.2846427   40.95629807  -0.70851062\n",
      "   8.39682296   0.5138452   -0.81461167  23.09773236  19.02039365\n",
      "  -0.40285816   0.23467238  -1.11874561  11.47690676   0.62868376\n",
      "   2.36056554 -10.2449669    0.8178833   -2.0630846   10.71816436\n",
      "  -1.97006266 -44.35212208   0.13293513   1.59086457   0.44705796\n",
      "  -4.17630175  -9.74249352  -0.05352464   0.09825471  17.7886363 ]\n",
      "iteration=70000, cost=4257821.954911671\n",
      "[  2.18319229 -27.16600505 -23.61785677  40.5611535   -0.69520596\n",
      "   7.81739348   0.52682375  -0.79768471  23.07398649  19.05581901\n",
      "  -0.4029994    0.2345746   -1.10704648  11.7547106    0.62926524\n",
      "   2.35738938 -10.04590075   0.81827819  -2.05316957  10.55528004\n",
      "  -1.96659399 -42.95224885   0.13740149   1.53995382   0.70819611\n",
      "  -3.90875372  -9.71850189  -0.04425146   0.10456104  17.3471924 ]\n",
      "iteration=80000, cost=4089331.9459577734\n",
      "[  1.89950077 -26.96750934 -23.02942637  40.11178548  -0.52502346\n",
      "   7.158551     0.70015669  -0.78249555  23.05129878  18.92358214\n",
      "  -0.40262554   0.23365152  -0.93740155  11.97258591   0.6285898\n",
      "   2.35455913  -9.87320801   0.81790168  -2.04553039  10.37901617\n",
      "  -1.96435287 -41.87556343   0.14093005   1.19309753   0.74810917\n",
      "  -3.86291313  -9.56401043   0.12260913   0.26910226  16.82438777]\n",
      "iteration=90000, cost=3974408.373326392\n",
      "3323.0\n",
      "training accuracy = 0.6646\n"
     ]
    }
   ],
   "source": [
    "def sgd_for_svm_demo(y, X):\n",
    "    \n",
    "    max_iter = 100000\n",
    "    gamma = 1\n",
    "    lambda_ = 0.01\n",
    "    \n",
    "    num_examples, num_features = X.shape\n",
    "    w = np.zeros(num_features)\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # n = sample one data point uniformly at random data from x\n",
    "        n = random.randint(0,num_examples-1)\n",
    "        \n",
    "        grad = calculate_stochastic_gradient(y, X, w, lambda_, n, num_examples)\n",
    "        w -= gamma/(it+1) * grad\n",
    "        \n",
    "        if it % 10000 == 0:\n",
    "            cost = calculate_primal_objective(y, X, w, lambda_)\n",
    "            print(\"iteration={i}, cost={c}\".format(i=it, c=cost))\n",
    "    \n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, X, w)))\n",
    "\n",
    "sgd_for_svm_demo(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Descent (Ascent) for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the closed-form update for the n-th variable alpha, in the dual optimization problem, given alpha and the current corresponding w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_coordinate_update(y, X, lambda_, alpha, w, n):\n",
    "    \"\"\"compute a coordinate update (closed form) for coordinate n.\n",
    "    X: the dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    n: the coordinate to be updated\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    # calculate the update of coordinate at index=n.\n",
    "    x_n, y_n = X[n], y[n]\n",
    "    old_alpha_n = np.copy(alpha[n])\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    return w, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_dual_objective(y, X, w, alpha, lambda_):\n",
    "    \"\"\"calculate the objective for the dual problem.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def coordinate_descent_for_svm_demo(y, X):\n",
    "    max_iter = 100000\n",
    "    lambda_ = 0.01\n",
    "\n",
    "    num_examples, num_features = X.shape\n",
    "    w = np.zeros(num_features)\n",
    "    alpha = np.zeros(num_examples)\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # n = sample one data point uniformly at random data from x\n",
    "        n = random.randint(0,num_examples-1)\n",
    "        \n",
    "        w, alpha = calculate_coordinate_update(y, X, lambda_, alpha, w, n)\n",
    "            \n",
    "        if it % 10000 == 0:\n",
    "            # primal objective\n",
    "            primal_value = calculate_primal_objective(y, X, w, lambda_)\n",
    "            # dual objective\n",
    "            dual_value = calculate_dual_objective(y, X, w, alpha, lambda_)\n",
    "            # primal dual gap\n",
    "            duality_gap = primal_value - dual_value\n",
    "            print('iteration=%i, primal:%.5f, dual:%.5f, gap:%.5f'%(\n",
    "                    it, primal_value, dual_value, duality_gap))\n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, X, w)))\n",
    "\n",
    "coordinate_descent_for_svm_demo(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
